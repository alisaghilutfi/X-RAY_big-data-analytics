{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of this work is inspired by the wonderful kernel 'Train Simple XRay CNN' by Kevin Mader\n",
    "# Some code fragments are sourced or adapted directly from this Kernel\n",
    "# I cite his work when appropriate, including URL/Dates, and it can also be referenced here: https://www.kaggle.com/kmader/train-simple-xray-cnn\n",
    "\n",
    "# Much of my thinking is also guided by Google's nice explanation of AutoML for Vision. General principles are quite useful\n",
    "# https://cloud.google.com/vision/automl/docs/beginners-guide\n",
    "\n",
    "# Lastly, I found this article on how AI is changing radiology imaging quite interesting\n",
    "# https://healthitanalytics.com/news/how-artificial-intelligence-is-changing-radiology-pathology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "# load help packages\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # basic plotting\n",
    "import seaborn as sns # additional plotting functionality\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running the below code (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "print(os.listdir(\"XRAY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "xray_data = pd.read_csv('XRAY/Data_Entry_2017.csv')\n",
    "\n",
    "# see how many observations there are\n",
    "num_obs = len(xray_data)\n",
    "print('Number of observations:',num_obs)\n",
    "\n",
    "# examine the raw data before performing pre-processing\n",
    "xray_data.head(5) # view first 5 rows\n",
    "#xray_data.sample(5) # view 5 randomly sampled rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to learn this part from scratch, hadn't gone so deep into file paths before!\n",
    "# looked at glob & os documentation, along with Kevin's methodology to get this part working\n",
    "# note: DON'T adjust this code, it's short but took a long time to get right\n",
    "# https://docs.python.org/3/library/glob.html\n",
    "# https://docs.python.org/3/library/os.html\n",
    "# https://www.geeksforgeeks.org/os-path-module-python/ \n",
    "    \n",
    "from glob import glob\n",
    "#import os # already imported earlier\n",
    "\n",
    "my_glob = glob('XRAY/images*/images/*.png')\n",
    "print('Number of Observations: ',len(my_glob)) # check to make sure I've captured every pathway, should equal 112,120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the image paths onto xray_data\n",
    "# Credit: small helper code fragment adapted from Kevin Mader - Simple XRay CNN on 12/09/18\n",
    "# https://www.kaggle.com/kmader/train-simple-xray-cnn\n",
    "full_img_paths = {os.path.basename(x): x for x in my_glob}\n",
    "xray_data['full_path'] = xray_data['Image Index'].map(full_img_paths.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset a bit\n",
    "\n",
    "# Q: how many unique labels are there? A: many (836) because of co-occurence\n",
    "# Note: co-occurence will turn out to be a real pain to deal with later, but there are several techniques that help us work with\n",
    "# it successfully\n",
    "num_unique_labels = xray_data['Finding Labels'].nunique()\n",
    "print('Number of unique labels:',num_unique_labels)\n",
    "\n",
    "# let's look at the label distribution to better plan our next step\n",
    "count_per_unique_label = xray_data['Finding Labels'].value_counts() # get frequency counts per label\n",
    "df_count_per_unique_label = count_per_unique_label.to_frame() # convert series to dataframe for plotting purposes\n",
    "\n",
    "print(df_count_per_unique_label) # view tabular results\n",
    "sns.barplot(x=df_count_per_unique_label.index[:20],y=\"Finding Labels\",data=df_count_per_unique_label[:20],color=\"green\"),plt.xticks(rotation=90) # visualize results graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dummy labels for one hot encoding - simplifying to 14 primary classes (excl. No Finding)\n",
    "dummy_labels = ['Atelectasis','Consolidation','Infiltration','Pneumothorax','Edema','Emphysema','Fibrosis','Effusion','Pneumonia','Pleural_Thickening', \n",
    "'Cardiomegaly','Nodule','Mass','Hernia'] # taken from paper\n",
    "\n",
    "# One Hot Encoding of Finding Labels to dummy_labels\n",
    "for label in dummy_labels:\n",
    "    xray_data[label] = xray_data['Finding Labels'].map(lambda result: 1.0 if label in result else 0)\n",
    "xray_data.head(20) # check the data, looking good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's see how many cases present for each of of our 14 clean classes (which excl. 'No Finding')\n",
    "clean_labels = xray_data[dummy_labels].sum().sort_values(ascending= False) # get sorted value_count for clean labels\n",
    "print(clean_labels) # view tabular results\n",
    "\n",
    "# plot cases using seaborn barchart\n",
    "clean_labels_df = clean_labels.to_frame() # convert to dataframe for plotting purposes\n",
    "sns.barplot(x=clean_labels_df.index[::],y=0,data=clean_labels_df[::],color=\"green\"),plt.xticks(rotation=90) # visualize results graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL CREATION PHASE STARTS HERE\n",
    "\n",
    "# create vector as ground-truth, will use as actuals to compare against our predictions later\n",
    "xray_data['target_vector'] = xray_data.apply(lambda target:[target[dummy_labels].values],1).map(lambda target:target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xray_data.head() # take a look to ensure target_vector makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(xray_data,test_size=0.2,random_state=1993)\n",
    "\n",
    "# quick check to see that the training and test set were split properly\n",
    "print('training set - # of observations: ',len(train_set))\n",
    "print('test set - # of observations): ',len(test_set))\n",
    "print('prior, full data set - # of observations): ',len(xray_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PRE-PROCESSING\n",
    "# See Keras documentation: https://keras.io/preprocessing/image/\n",
    "\n",
    "# Create ImageDataGenerator, to perform significant image augmentation\n",
    "# Utilizing most of the parameter options to make the image data even more robust\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "data_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: Helper function for image augmentation - Code sourced directly from Kevin Mader - Simple XRay CNN on 12/09/18\n",
    "# https://www.kaggle.com/kmader/train-simple-xray-cnn\n",
    "\n",
    "# This Flow_from function is actually based on the default function from Keras '.flow_from_dataframe', but is more flexible\n",
    "# Base function reference: https://keras.io/preprocessing/image/\n",
    "# Specific notes re function: https://github.com/keras-team/keras/issues/5152\n",
    "\n",
    "def flow_from_dataframe(img_data_gen,in_df,path_col,y_col,**dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode ='sparse',\n",
    "                                     **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use flow_from_dataframe() for training and validation - simply pass arguments through to function parameters\n",
    "# Credit: Code adapted from Kevin Mader - Simple XRay CNN on 12/09/18\n",
    "# https://www.kaggle.com/kmader/train-simple-xray-cnn\n",
    "\n",
    "image_size = (128,128) # image re-sizing target\n",
    "train_gen = flow_from_dataframe(data_gen,train_set,path_col='full_path',y_col='target_vector',target_size=image_size,\n",
    "                                color_mode='grayscale',batch_size=32)\n",
    "valid_gen = flow_from_dataframe(data_gen,test_set,path_col='full_path',y_col='target_vector',target_size=image_size,\n",
    "                                color_mode='grayscale',batch_size=128)\n",
    "\n",
    "# define test sets\n",
    "test_X, test_Y = next(flow_from_dataframe(data_gen,test_set,path_col='full_path',y_col='target_vector',target_size=image_size,\n",
    "                                          color_mode='grayscale',batch_size = 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On to the fun stuff! Create a convolutional neural network model to train from scratch\n",
    "\n",
    "# Import relevant libraries\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create CNN model\n",
    "# Will use a combination of convolutional, max pooling, and dropout layers for this purpose\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 8, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = test_X.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "          \n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "          \n",
    "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 3))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# add in fully connected dense layers to model, then output classifiction probabilities using a softmax activation function\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(dummy_labels), activation = 'softmax'))\n",
    "\n",
    "# compile model, run summary\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a checkpoint for model training\n",
    "# https://keras.io/callbacks/\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only = True)\n",
    "callbacks_list = [checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model!\n",
    "# Note: This first model will be fitted very quickly, will fit a higher accuracy modelthat requires more training time after this\n",
    "# Documentation: https://keras.io/models/model/\n",
    "model.fit_generator(generator=train_gen,steps_per_epoch=20,epochs=1,callbacks=callbacks_list,validation_data=(test_X,test_Y))\n",
    "\n",
    "## How I decided which fit function to use\n",
    "# model.fit_generator() v. model.fit() - https://datascience.stackexchange.com/questions/34444/what-is-the-difference-between-fit-and-fit-generator-in-keras\n",
    "# 2nd good example: https://medium.com/difference-engine-ai/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2\n",
    "# Basically, for large data-sets like this one, it's best-practice to use model.fit_generator()\n",
    "# This is because i) dataset can't be loaded into memory all at once, ii) we're already doing image augmentation, so this solution meshes nicely\n",
    "# Takeaway - use model.fit_generator() for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction based on our fitted model\n",
    "quick_model_predictions = model.predict(test_X,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit: Helper function for Plotting - Code sourced directly from Kevin Mader - Simple XRay CNN on 12/09/18\n",
    "# https://www.kaggle.com/kmader/train-simple-xray-cnn\n",
    "\n",
    "# import libraries\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# create plot\n",
    "fig, c_ax = plt.subplots(1,1,figsize=(9,9))\n",
    "for (i,label) in enumerate(dummy_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,i].astype(int),quick_model_predictions[:,i])\n",
    "    c_ax.plot(fpr,tpr,label='%s (AUC:%0.2f)'  % (label,auc(fpr,tpr)))\n",
    "\n",
    "# Set labels for plot\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('quick_trained_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See previous code snippets for all references\n",
    "\n",
    "# Run a longer, more detailed model\n",
    "model.fit_generator(generator=train_gen,steps_per_epoch=50,epochs=5,callbacks=callbacks_list,validation_data=(test_X,test_Y))\n",
    "\n",
    "# Make prediction based on our fitted model\n",
    "deep_model_predictions = model.predict(test_X,batch_size=64,verbose=1)\n",
    "\n",
    "# create plot\n",
    "fig, c_ax = plt.subplots(1,1,figsize=(9,9))\n",
    "for (i, label) in enumerate(dummy_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,i].astype(int), deep_model_predictions[:,i])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (label, auc(fpr, tpr)))\n",
    "\n",
    "# Set labels for plot\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('deep_trained_model.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
